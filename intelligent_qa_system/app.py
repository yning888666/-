"""
å¤šåŠŸèƒ½æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
æ•´åˆè±†åŒ…APIã€æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘
"""
from flask import Flask, render_template, request, jsonify
from doubao_api import DoubaoAPI
from nlp_models import NLPModels
import re


# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__, static_url_path='/static')

# åˆå§‹åŒ–è±†åŒ…API
DOUBAO_API_KEY = '5fe8c115-d78c-4fae-90be-6a2075f29f7e'
DOUBAO_MODEL = 'doubao-seed-1-6-lite-251015'
doubao = DoubaoAPI(DOUBAO_API_KEY, DOUBAO_MODEL)

# åˆå§‹åŒ–NLPæ¨¡å‹
nlp_models = NLPModels()

# åŠ è½½æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
print("=" * 60)
print("æ­£åœ¨åˆå§‹åŒ–å¤šåŠŸèƒ½æ™ºèƒ½é—®ç­”ç³»ç»Ÿ...")
print("=" * 60)
print("\næ­£åœ¨åŠ è½½NLPæ¨¡å‹...")
try:
    if nlp_models.load_text_classifier():
        print("  âœ“ æ–‡æœ¬åˆ†ç±»æ¨¡å‹å·²åŠ è½½")
    else:
        print("  âœ— æ–‡æœ¬åˆ†ç±»æ¨¡å‹ä¸å¯ç”¨ï¼ˆå°†è·³è¿‡åˆ†ç±»åŠŸèƒ½ï¼‰")
except Exception as e:
    print(f"  âœ— æ–‡æœ¬åˆ†ç±»æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

try:
    if nlp_models.load_sentiment_analyzer():
        print("  âœ“ æƒ…æ„Ÿåˆ†æè¯å…¸å·²æ„å»º")
    else:
        print("  âœ— æƒ…æ„Ÿåˆ†æè¯å…¸ä¸å¯ç”¨ï¼ˆå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼‰")
except Exception as e:
    print(f"  âœ— æƒ…æ„Ÿåˆ†æè¯å…¸åŠ è½½å¤±è´¥: {str(e)}")

print("\nâœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
print("=" * 60)
print("åŠŸèƒ½åŒ…æ‹¬ï¼š")
print("  1. ğŸ¤– è±†åŒ…APIæ™ºèƒ½é—®ç­”")
print("  2. ğŸ“Š æ–‡æœ¬åˆ†ç±»ï¼ˆ10ä¸ªç±»åˆ«ï¼‰")
print("  3. ğŸ˜Š æƒ…æ„Ÿåˆ†æï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰")
print("  4. ğŸŒ æœºå™¨ç¿»è¯‘ï¼ˆä½¿ç”¨è±†åŒ…APIï¼‰")
print("  5. ğŸ¯ æ™ºèƒ½æ„å›¾è¯†åˆ«")
print("=" * 60)
print("\nç³»ç»Ÿå°†åœ¨ http://127.0.0.1:8808 å¯åŠ¨\n")


def detect_function(user_input):
    """æ™ºèƒ½æ£€æµ‹ç”¨æˆ·æ„å›¾ï¼Œåˆ¤æ–­åº”è¯¥ä½¿ç”¨å“ªä¸ªåŠŸèƒ½"""
    user_input_lower = user_input.lower()
    
    # ç¿»è¯‘æ„å›¾å…³é”®è¯
    translate_keywords = ['ç¿»è¯‘', 'translate', 'è¯‘æˆ', 'è½¬æ¢æˆ', 'ç¿»è¯‘æˆ']
    if any(keyword in user_input or keyword.lower() in user_input_lower for keyword in translate_keywords):
        return 'translate'
    
    # æƒ…æ„Ÿåˆ†ææ„å›¾å…³é”®è¯
    sentiment_keywords = ['æƒ…æ„Ÿ', 'æƒ…ç»ª', 'æ„Ÿè§‰', 'sentiment', 'å¿ƒæƒ…', 'æ€åº¦', 'è¯„ä»·']
    if any(keyword in user_input or keyword.lower() in user_input_lower for keyword in sentiment_keywords):
        return 'sentiment'
    
    # æ–‡æœ¬åˆ†ç±»æ„å›¾å…³é”®è¯
    classify_keywords = ['åˆ†ç±»', 'ç±»åˆ«', 'å±äº', 'æ˜¯ä»€ä¹ˆç±»å‹', 'category', 'classify']
    if any(keyword in user_input or keyword.lower() in user_input_lower for keyword in classify_keywords):
        return 'classify'
    
    # å¦‚æœåŒ…å«ä¸­è‹±æ–‡æ··åˆï¼Œå¯èƒ½æ˜¯ç¿»è¯‘éœ€æ±‚
    has_chinese = any('\u4e00' <= char <= '\u9fff' for char in user_input)
    has_english = bool(re.search(r'[a-zA-Z]', user_input))
    if has_chinese and has_english and len(user_input) < 50:
        return 'translate'
    
    # é»˜è®¤ä½¿ç”¨é—®ç­”
    return 'qa'


def format_response_with_analysis(user_input, reply, classification=None, sentiment=None):
    """æ ¼å¼åŒ–å›å¤ï¼ŒåŒ…å«åˆ†æç»“æœ"""
    response_parts = []
    
    # æ·»åŠ ä¸»è¦å›å¤
    response_parts.append(reply)
    
    # æ·»åŠ åˆ†ç±»ç»“æœ
    if classification:
        category = classification.get('category', 'æœªçŸ¥')
        confidence = classification.get('confidence', 0)
        response_parts.append(f"\nğŸ“Š æ–‡æœ¬åˆ†ç±»: {category} (ç½®ä¿¡åº¦: {confidence:.2%})")
    
    # æ·»åŠ æƒ…æ„Ÿåˆ†æç»“æœ
    if sentiment:
        sentiment_type = sentiment.get('sentiment', 'æœªçŸ¥')
        sentiment_conf = sentiment.get('confidence', 0)
        response_parts.append(f"ğŸ˜Š æƒ…æ„Ÿåˆ†æ: {sentiment_type} (ç½®ä¿¡åº¦: {sentiment_conf:.2%})")
    
    return "\n".join(response_parts)


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')


@app.route('/message', methods=['POST'])
def reply():
    """æ™ºèƒ½é—®ç­”æ¥å£"""
    try:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_msg = request.form.get('msg', '').strip()
        
        if not user_msg:
            return jsonify({'text': 'è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–éœ€è¦å¤„ç†çš„å†…å®¹ã€‚', 'type': 'error'})
        
        # æ£€æµ‹ç”¨æˆ·æ„å›¾
        function_type = detect_function(user_msg)
        
        result = {
            'text': '',
            'type': function_type,
            'analysis': {}
        }
        
        # æ ¹æ®æ„å›¾æ‰§è¡Œç›¸åº”åŠŸèƒ½
        if function_type == 'translate':
            # ç¿»è¯‘åŠŸèƒ½
            translate_text = user_msg
            for keyword in ['ç¿»è¯‘', 'translate', 'è¯‘æˆ', 'è½¬æ¢æˆ', 'ç¿»è¯‘æˆ']:
                if keyword in translate_text:
                    translate_text = translate_text.split(keyword)[-1].strip()
                    break
            
            # åˆ¤æ–­ç›®æ ‡è¯­è¨€
            target_lang = 'en'
            if 'è‹±æ–‡' in user_msg or 'english' in user_msg.lower() or 'è‹±è¯­' in user_msg:
                target_lang = 'en'
            elif 'ä¸­æ–‡' in user_msg or 'chinese' in user_msg.lower() or 'æ±‰è¯­' in user_msg:
                target_lang = 'zh'
            
            # ä½¿ç”¨è±†åŒ…APIè¿›è¡Œç¿»è¯‘
            translation = doubao.translate(translate_text, target_lang)
            result['text'] = f"ğŸŒ ç¿»è¯‘ç»“æœ:\nåŸæ–‡: {translation['original']}\nè¯‘æ–‡: {translation['translated']}"
            result['analysis']['translation'] = translation
        
        elif function_type == 'sentiment':
            # æƒ…æ„Ÿåˆ†æ
            analyze_text = user_msg
            for keyword in ['æƒ…æ„Ÿ', 'æƒ…ç»ª', 'æ„Ÿè§‰', 'sentiment', 'å¿ƒæƒ…', 'æ€åº¦', 'è¯„ä»·']:
                if keyword in analyze_text:
                    analyze_text = analyze_text.split(keyword)[-1].strip()
                    break
            
            sentiment_result = nlp_models.analyze_sentiment(analyze_text)
            if sentiment_result:
                sentiment_type = sentiment_result.get('sentiment', 'æœªçŸ¥')
                sentiment_conf = sentiment_result.get('confidence', 0)
                pos_words = sentiment_result.get('positive_words', 0)
                neg_words = sentiment_result.get('negative_words', 0)
                
                emoji = 'ğŸ˜Š' if sentiment_type == 'æ­£é¢' else 'ğŸ˜' if sentiment_type == 'è´Ÿé¢' else 'ğŸ˜'
                result['text'] = f"{emoji} æƒ…æ„Ÿåˆ†æç»“æœ:\næƒ…æ„Ÿå€¾å‘: {sentiment_type}\nç½®ä¿¡åº¦: {sentiment_conf:.2%}\næ­£é¢è¯æ±‡æ•°: {pos_words}\nè´Ÿé¢è¯æ±‡æ•°: {neg_words}"
                result['analysis']['sentiment'] = sentiment_result
            else:
                result['text'] = "æƒ…æ„Ÿåˆ†æåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        
        elif function_type == 'classify':
            # æ–‡æœ¬åˆ†ç±»
            classify_text = user_msg
            for keyword in ['åˆ†ç±»', 'ç±»åˆ«', 'å±äº', 'æ˜¯ä»€ä¹ˆç±»å‹', 'category', 'classify']:
                if keyword in classify_text:
                    classify_text = classify_text.split(keyword)[-1].strip()
                    break
            
            classification_result = nlp_models.classify_text(classify_text)
            if classification_result:
                category = classification_result.get('category', 'æœªçŸ¥')
                confidence = classification_result.get('confidence', 0)
                result['text'] = f"ğŸ“Š æ–‡æœ¬åˆ†ç±»ç»“æœ:\nç±»åˆ«: {category}\nç½®ä¿¡åº¦: {confidence:.2%}"
                result['analysis']['classification'] = classification_result
            else:
                result['text'] = "æ–‡æœ¬åˆ†ç±»åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        
        else:
            # é»˜è®¤ï¼šæ™ºèƒ½é—®ç­” + è‡ªåŠ¨åˆ†æ
            qa_result = doubao.chat(user_msg)
            
            if qa_result['success']:
                reply_text = qa_result['reply']
                
                # è‡ªåŠ¨æ‰§è¡Œæ–‡æœ¬åˆ†ç±»å’Œæƒ…æ„Ÿåˆ†æ
                classification = nlp_models.classify_text(user_msg)
                sentiment = nlp_models.analyze_sentiment(user_msg)
                
                # ç»„åˆå›å¤
                result['text'] = format_response_with_analysis(user_msg, reply_text, classification, sentiment)
                result['analysis']['classification'] = classification
                result['analysis']['sentiment'] = sentiment
            else:
                result['text'] = f"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚é”™è¯¯ä¿¡æ¯: {qa_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({
            'text': f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}',
            'type': 'error'
        })


@app.route('/analyze', methods=['POST'])
def analyze():
    """ä¸“é—¨çš„æ–‡æœ¬åˆ†ææ¥å£"""
    try:
        text = request.form.get('text', '').strip()
        analysis_type = request.form.get('type', 'all')
        
        if not text:
            return jsonify({'error': 'è¯·æä¾›è¦åˆ†æçš„æ–‡æœ¬'})
        
        result = {}
        
        if analysis_type in ['all', 'classify']:
            classification = nlp_models.classify_text(text)
            result['classification'] = classification
        
        if analysis_type in ['all', 'sentiment']:
            sentiment = nlp_models.analyze_sentiment(text)
            result['sentiment'] = sentiment
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': str(e)})


@app.route('/translate', methods=['POST'])
def translate():
    """ä¸“é—¨çš„ç¿»è¯‘æ¥å£"""
    try:
        text = request.form.get('text', '').strip()
        target_lang = request.form.get('target_lang', 'en')
        
        if not text:
            return jsonify({'error': 'è¯·æä¾›è¦ç¿»è¯‘çš„æ–‡æœ¬'})
        
        translation = doubao.translate(text, target_lang)
        return jsonify(translation)
    
    except Exception as e:
        return jsonify({'error': str(e)})


if __name__ == '__main__':
    app.run(host='127.0.0.1', port=8808, debug=True)
